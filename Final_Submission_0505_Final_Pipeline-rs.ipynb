{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group number:** 1 <br>\n",
    "**Student IDs:** 48725, 48483, 48481, 49036 <br>\n",
    "**Project name:** Ad Clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA and More\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#Graphic Parameter Display\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "#Splitting Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Pipeline and GridSearch\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#Balancing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#Preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import SelectPercentile,  mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "#Saving Models outside notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>app_category</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_ip</th>\n",
       "      <th>device_model</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.448465e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102806</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>d6137915</td>\n",
       "      <td>bb1ef334</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>a506b0a5</td>\n",
       "      <td>9efa421a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19771</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2227</td>\n",
       "      <td>0</td>\n",
       "      <td>935</td>\n",
       "      <td>-1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.342805e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102307</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9a08a110</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>0fb3da37</td>\n",
       "      <td>73075152</td>\n",
       "      <td>02d14ecc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21676</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2495</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.048699e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102310</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>9a28a858</td>\n",
       "      <td>64778742</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>1847b3fb</td>\n",
       "      <td>ecb851b2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21837</td>\n",
       "      <td>300</td>\n",
       "      <td>250</td>\n",
       "      <td>2523</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.833733e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102307</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>9ac6509a</td>\n",
       "      <td>779d90c2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.035453e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102811</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>a5184c22</td>\n",
       "      <td>b8d325c3</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>cfeed5cf</td>\n",
       "      <td>dc15c87e</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23224</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2676</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100176</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
       "0  6.448465e+18      0  14102806  1005           0  d6137915    bb1ef334   \n",
       "1  1.342805e+19      0  14102307  1002           0  85f751fd    c4e18dd6   \n",
       "2  1.048699e+19      0  14102310  1005           0  9a28a858    64778742   \n",
       "3  8.833733e+18      0  14102307  1005           0  1fbe01fe    f3845767   \n",
       "4  1.035453e+19      0  14102811  1005           0  85f751fd    c4e18dd6   \n",
       "\n",
       "  site_category    app_id app_domain app_category device_id device_ip  \\\n",
       "0      f028772b  ecad2386   7801e8d9     07d7df22  a99f214a  a506b0a5   \n",
       "1      50e219e0  9a08a110   7801e8d9     07d7df22  0fb3da37  73075152   \n",
       "2      f028772b  ecad2386   7801e8d9     07d7df22  a99f214a  1847b3fb   \n",
       "3      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a  9ac6509a   \n",
       "4      50e219e0  a5184c22   b8d325c3     0f2161f8  a99f214a  cfeed5cf   \n",
       "\n",
       "  device_model  device_type  device_conn_type    C14  C15  C16   C17  C18  \\\n",
       "0     9efa421a            1                 0  19771  320   50  2227    0   \n",
       "1     02d14ecc            0                 0  21676  320   50  2495    2   \n",
       "2     ecb851b2            1                 0  21837  300  250  2523    3   \n",
       "3     779d90c2            1                 0  15706  320   50  1722    0   \n",
       "4     dc15c87e            1                 2  23224  320   50  2676    0   \n",
       "\n",
       "   C19     C20  C21  \n",
       "0  935      -1   48  \n",
       "1  167      -1   23  \n",
       "2   39      -1  221  \n",
       "3   35      -1   79  \n",
       "4   35  100176  221  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data into dataframe\n",
    "df = pd.read_csv(\"ad_clicks_100k.csv\")\n",
    "\n",
    "#Check dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['click']\n",
    "X=df.drop(columns='click')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform hour column\n",
    "#First transform column into datetime format\n",
    "X['datetime'] = pd.to_datetime(X['hour'].astype(str), format='%y%m%d%H')\n",
    "#check first and last date\n",
    "X['datetime'].sort_values()\n",
    "# As all incidences are from year 2014 and month october\n",
    "# -> we decide to include only the hour and weekday in our model\n",
    "X[\"weekday\"] = X['datetime'].dt.day_of_week\n",
    "X[\"hour\"] = X['datetime'].dt.hour #as we name the new column hour we automatically drop the old hour column\n",
    "X.drop([\"datetime\"], axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ID column\n",
    "X.drop(columns=\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.5)\n",
    "\n",
    "print(\"Records in training dataset:\",X_train.shape[0],\"(\",(X_train.shape[0]/X.shape[0])*100,\"%)\")\n",
    "print(\"Records in test dataset:\",X_test.shape[0],\"(\",(X_test.shape[0]/X.shape[0])*100,\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline Steps:\n",
    "\n",
    "\n",
    "#### Balancing\n",
    "1. Balance Date\n",
    "    1. OverSampler\n",
    "    2. UnderSampler\n",
    "    3. No Balancing (\"passthrough)\n",
    "\n",
    "#### Feature Engineering\n",
    "##### Categorical Features:\n",
    "1. Select only Categorical Features (FeatureSelector(categorical_features)\n",
    "2. Reduction (Due to Processing Power)\n",
    "    1. Aggregate Categories (CategoryAggregator)\n",
    "    2. Exclude Features with many categories (BigFeatureExcluder)\n",
    "    3. No Reduction (\"passthrough\")\n",
    "3. Feature Encoding:\n",
    "    1. OneHot Encoding\n",
    "    2. Label Encoding\n",
    "    \n",
    "##### Ordinal Features:\n",
    "1. Select only numerical Features (FeatureSelector(numerical_features))\n",
    "2. Encode (OrdinalEncoder)\n",
    "3. Scale the numerical data (StandardScaler)\n",
    "\n",
    "Combine Both Feature sets (FeatureUnion)\n",
    "\n",
    "#### Feature Selection / Dimensionality Reduction\n",
    "\n",
    "1. Reduce Dimensionality/Select Features\n",
    "    1. Univariate Filtering\n",
    "    2. Model based using Log Reg\n",
    "    3. PCA\n",
    "    4. No Reduction (\"passthrough\") \n",
    "\n",
    "#### Models:\n",
    "\n",
    "1. Use Model to predict:\n",
    "    1. Linear Regression\n",
    "    2. Decison Tree\n",
    "    3. Random Forrest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Definiton of Columns Type for Pipeline:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
    "       'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n",
    "       'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n",
    "       'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "\n",
    "ordinal_features = ['hour', 'weekday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FeatureSelector takes a pandas dataframe and columns and returns dataframe with the given columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selector excludes categorical with more than max_cat=50 categories\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names, max_cat=50):\n",
    "        self.feature_names = feature_names\n",
    "        self.max_cat = max_cat\n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.feature_names].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CategoryAggregator aggregates features with large categories (more categories per feature than defined threshold), and takes all categories into account which cover till a certeain percentile, and aggregates all categories below percentile threshold as one category other.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryAggregator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, agg_percentil=0.7, agg_threshold=10, cat_limit=True, max_cat=50):\n",
    "        self.top_categories = {}\n",
    "        self.feature_names = []\n",
    "        self.agg_percentil = agg_percentil\n",
    "        self.agg_threshold = agg_threshold\n",
    "        self.max_cat = max_cat\n",
    "        self.cat_limit = cat_limit\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        #Create a list of the top percentil categories and aggregate them, skip features with <= treshold\n",
    "        self.feature_names = list(X.columns)\n",
    "        for col in X[self.feature_names]:\n",
    "            if X[col].nunique() <= self.agg_threshold:\n",
    "                self.top_categories[col] = list(X[col].unique())\n",
    "            else:\n",
    "                feature = pd.DataFrame(X[col].value_counts()/X.shape[0])\n",
    "                feature[\"cumsum\"] = feature.cumsum()\n",
    "                categories = list(feature.loc[feature[\"cumsum\"] < self.agg_percentil].index)\n",
    "                if self.cat_limit == True:\n",
    "                    if len(categories) > self.max_cat:\n",
    "                        print(\"Feature\",col,\"has after aggregation\",\"(with agg_percentil=\",self.agg_percentil,\")\", len(categories), \"categories and is excluded.\")\n",
    "                else:\n",
    "                    self.top_categories[col] = list(feature.loc[feature[\"cumsum\"] < self.agg_percentil].index)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_output = X.loc[:, self.feature_names].copy(deep=True)\n",
    "        for col, categories in self.top_categories.items():\n",
    "            if (X_output[col].dtype == 'int64'):\n",
    "                X_output.loc[~X[col].isin(categories), col] = -10\n",
    "            else:\n",
    "                X_output.loc[~X[col].isin(categories), col] = \"other\" \n",
    "        return X_output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BigFeatureExcluder excludes categorical with more categories then defined (max_cat):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#BigFeatureExcluder excludes categorical with more than max_cat=50 categories\n",
    "class BigFeatureExcluder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_cat=50):\n",
    "        self.feature_names = []\n",
    "        self.max_cat = max_cat\n",
    "    def fit( self, X, y = None):\n",
    "        #Identfy relevant features, features with less than 50 categories\n",
    "        self.feature_names = list(X.columns)\n",
    "        less_categories = []\n",
    "        for col in X[self.feature_names]:\n",
    "            if X[self.feature_names][col].nunique() < self.max_cat:\n",
    "                less_categories.append(col)\n",
    "        self.feature_names = less_categories\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.feature_names].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The Pipeline Main Construct:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline - WORKING\n",
    "\n",
    "# Preprocessing\n",
    "## Feature Engineering\n",
    "#categorical pipeline OneHotEncoder\n",
    "categorical_pipeline = Pipeline(steps = [ \n",
    "    (\"column_selector\", FeatureSelector(categorical_features)),\n",
    "    (\"reduction\", CategoryAggregator(agg_percentil=0.7, agg_threshold=10, cat_limit=True, max_cat=30)),\n",
    "    (\"encoding\", OneHotEncoder(drop=\"first\", handle_unknown='ignore', sparse=False)) \n",
    "])\n",
    "\n",
    "\n",
    "ordinal_pipeline = Pipeline(steps = [ \n",
    "    (\"column_selector\", FeatureSelector(ordinal_features)),\n",
    "    (\"encoding\", OrdinalEncoder()),\n",
    "    (\"std_scaler\", StandardScaler()) \n",
    "])\n",
    "\n",
    "\n",
    "feature_engine_pipe = FeatureUnion(transformer_list=([(\"ordinal_pipe\", ordinal_pipeline),\n",
    "                                                      (\"categorical_pipe\", categorical_pipeline)]),\n",
    "                                   n_jobs=-1, )\n",
    "#Main Pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('balancing', RandomUnderSampler()),\n",
    "    (\"feature_engineering\", feature_engine_pipe),\n",
    "    (\"feature_selection\", SelectPercentile(f_classif,  percentile=50)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAM GRID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "_Hyperparameters tuned: C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1a = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectPercentile(mutual_info_classif,  percentile=50)],\n",
    "          \"feature_selection__percentile\": [50,65,80],\n",
    "          \"model\":[LogisticRegression()],\n",
    "          \"model__C\":[0.1, 1.0, 10]}\n",
    "\n",
    "param1b = {\"balancing\": [RandomUnderSampler(),RandomOverSampler(), 'passthrough'],\n",
    "          \"feature_selection\": [SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', random_state=42))],\n",
    "          \"feature_selection__estimator__C\": [0.1, 1.0, 10],\n",
    "          \"model\":[LogisticRegression()],\n",
    "          \"model__C\":[0.1, 1.0, 10]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Possible Parameter Combinations:__ Balancing x Feature Engineering x Feature Selection x Model\n",
    "\n",
    "Param1a: 2 x 1 x 3 x 3 = 18\n",
    "\n",
    "Param1b: 2 x 1 x 3 x 3 = 18\n",
    "\n",
    "__Total: 36__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "_Hyperparameters tuned: max depth of tree, min samples leaf and criterion_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param2a = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectPercentile(mutual_info_classif,  percentile=50)],\n",
    "          \"feature_selection__percentile\": [50,65,80],\n",
    "          'model': [DecisionTreeClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_samples_leaf': [5, 6, 7, 8, 9],\n",
    "          'model__criterion': ['gini', 'entropy']}\n",
    "\n",
    "\n",
    "param2b = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', random_state=42))],\n",
    "          \"feature_selection__estimator__C\": [0.1, 1.0, 10],\n",
    "          'model': [DecisionTreeClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_samples_leaf': [5, 6, 7, 8, 9],\n",
    "          'model__criterion': ['gini', 'entropy']}\n",
    "\n",
    "param2c = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [\"passthrough\"],\n",
    "          'model': [DecisionTreeClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_samples_leaf': [5, 6, 7, 8, 9],\n",
    "          'model__criterion': ['gini', 'entropy']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter Combinations:__ Balancing x Feature Engineering x Feature Selection x Model\n",
    "\n",
    "Param2a: 2 x 1 x 3 x (4x5x2=40) = 240\n",
    "\n",
    "Param2b: 2 x 1 x 3 x (4x5x2=40) = 80\n",
    "\n",
    "Param2c: 2 x 1 x 1 x (4x5x2=40) = 80\n",
    "\n",
    "__Total: 400__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest\n",
    "Hyperparameters tuned: max depth and number of estimators - #add others??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param3a = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectPercentile(mutual_info_classif,  percentile=50)],\n",
    "          \"feature_selection__percentile\": [50,65,80],\n",
    "          'model': [RandomForestClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__criterion': ['gini', 'entropy'],\n",
    "          'model__n_estimators': list(np.arange(100,600,100))}\n",
    "\n",
    "\n",
    "param3b = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', random_state=42))],\n",
    "          \"feature_selection__estimator__C\": [0.1, 1.0, 10],          \n",
    "          'model': [RandomForestClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__criterion': ['gini', 'entropy'],\n",
    "          'model__n_estimators': list(np.arange(100,600,100))}\n",
    "\n",
    "\n",
    "param3c = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [\"passthrough\"],\n",
    "          'model': [RandomForestClassifier()],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__criterion': ['gini', 'entropy'],\n",
    "          'model__n_estimators': list(np.arange(100,600,100))}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter Combinations:__ Balancing x Feature Engineering x Feature Selection x Model\n",
    "\n",
    "Param3a: 2 x 1 x 3 x (4x2x5=40) = 240\n",
    "\n",
    "Param3b: 2 x 1 x 3 x (4x2x5=40) = 80\n",
    "\n",
    "Param3c: 2 x 1 x 1 x (4x2x5=40) = 80\n",
    "\n",
    "__Total: 400__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Boost\n",
    "_Hyperparameters tuned: learning rate, max tree depth - #add others??_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param4a = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectPercentile(mutual_info_classif,  percentile=50)],\n",
    "          \"feature_selection__percentile\": [50,65,80],\n",
    "          'model': [XGBClassifier()],\n",
    "          'model__learning_rate':[0.001,0.01,0.1],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_child_weight': [0.5, 1.0, 3.0, 5.0]}\n",
    "\n",
    "\n",
    "param4b = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', random_state=42))],\n",
    "          \"feature_selection__estimator__C\": [0.1, 1.0, 10],\n",
    "          'model': [XGBClassifier()],\n",
    "          'model__learning_rate': [0.001,0.01,0.1],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_child_weight': [0.5, 1.0, 3.0, 5.0]}\n",
    "\n",
    "param4c = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_selection\": [\"passthrough\"],\n",
    "          'model': [XGBClassifier()],\n",
    "          'model__learning_rate':[0.001,0.01,0.1],\n",
    "          'model__max_depth': [3, 5, 7, 9],\n",
    "          'model__min_child_weight': [0.5, 1.0, 3.0, 5.0]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter Combinations:__ Balancing x Feature Engineering x Feature Selection x Model\n",
    "\n",
    "Param4a: 2 x 1 x 3 x (3x4x4=48) = 288\n",
    "\n",
    "Param4b: 2 x 1 x 3 x (4x2x5=48) = 288\n",
    "\n",
    "Param4c: 2 x 1 x 1 x (4x2x5=48) = 96\n",
    "\n",
    "__Total: 672__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param5 = {\"balancing\": [RandomUnderSampler(),RandomOverSampler()],\n",
    "          \"feature_engineering__categorical_pipe__reduction\": [\"passthrough\"],\n",
    "          \"feature_selection\": ['passthrough'],\n",
    "          \"model\":[CatBoostClassifier(one_hot_max_size=50, logging_level='Silent')],\n",
    "          'model__learning_rate': [0.1,0.05,0.03,0.01],\n",
    "          'model__depth': [3, 5,7],\n",
    "          'model__l2_leaf_reg': [1, 3, 5, 7, 9]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter Combinations:__ Balancing x Feature Engineering x Feature Selection x Model\n",
    "\n",
    "Param5: 2 x 1 x 1 x (4x3x5=60) = 120\n",
    "\n",
    "__Total: 120__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combination of all parameter constellations for grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [param1a, param1b, \n",
    "              param2a, param2b, param2c, \n",
    "              param3a, param3b, param3c, \n",
    "              param4a, param4b, param4c, \n",
    "              param5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Total Cobinations:__ 36 + 400 + 400 + 672 + 120 = __1628__\n",
    "### In order to efficiently compute the model without using all parameters we will use Random Search with 30% x 1628 ≈ 500 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defintion of RandomSearch with 5 Crossfold Validations, meaning the models are 5 times validated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use balanced accuracy for evaluation of best model\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_grid, cv=5, scoring='f1', n_iter=500, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Model fit with test data:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Parameters for the best Estimator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Best cross-validation score ', random_search.best_score_)\n",
    "print('Test-set score:  ', random_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Top 10 Models:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "print(\"Tried\",results.shape[0],\"different Model constellations\")\n",
    "results.sort_values(by=[\"rank_test_score\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Important Outputs\n",
    "To be able to work on them after running & closing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'tuned_random_search.sav'\n",
    "pickle.dump(random_search, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load the model from disk\n",
    "filename = 'tuned_random_search.sav'\n",
    "random_search_run = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "random_search_run.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
